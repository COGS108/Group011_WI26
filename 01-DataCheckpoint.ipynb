{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "- Gianncarlo Sanchez: Background Research, Writing-original draft and reviewing/editing\n",
    "- Marisol Rodriguez: Background Research, Writing-original draft and reviewing/editing\n",
    "- Muhammad Kaaki:\n",
    "- Ray Santiago: Background Research, Writing-original draft and reviewing/editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the seasons of the year impact the type of music that appears on Billboard top 100 songs weekly in terms of valence, tempo, and energy, and how do these features compare to one another on a seasonal basis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music is grounded in *a priori* structures of human experience, so it goes. In essence, music is one of the most universal and accessible ways humans, and societies as a whole, encounter emotion and being. As Tomas Clifton describes in their work *Music and the a Priori*, musical experience contains its own form of understanding that is **immediately given** while listening<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1). These structuures are given in forms such as temporal flow, tension, and expectation, which are conditions of our existing in the world; They are not learned. It is because of this that we can call music a type of emotional landcape- A landscape that reveals how we experience and inhabit time, how we move through feeling, and how our inner states are susceptible to shift moment to moment, song-to-song. \n",
    "\n",
    "This persnal and deep connection between human emotion and music could offer an explanation for why some songs are described as energetic, uplifting, depressing, or calming<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). This account ***humanizes*** these labels, reflecting on how the music resonates with our own experiental structures, rather than seeming correlational and abstract. For example, faster tempos tend to evoke feelings of being upbeat or energetic while slower tempos can feel more calming or melancholic. Additionally, valence could lead us to label a song as either sad or happy, seemingly from our own intuition. Clifton's paper helps explain this intuitiveness, where music is directly tied to emotional meaning through structures that shape our experience of the world. \n",
    "\n",
    "The major point that our research project aims to address is the fact that emotional experience does not stay constant throughout the year. In the past couple decades, we have better come to understand environmental psychology by studying how seasonal changes in daylight, temperature, and daily routines can influence mood and motivation. The most obvious example of this comes from the term **winter depression**, a.k.a. Seasonal Affective Disorder. \n",
    "\n",
    "As Yale School of Medicine describes, SAD is characterized by dperessed mood, decreased enjoyment of activities, sadness, poor energy, and decreased confidence. Most importantly for our research question, through questionaires they note that roughly 90% of people claim to report changes in energy, modd, sleep, and apetite in the winter<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). This pattern typically starts in fall, seemingly creating a pattern of a rise and decline of mood and emotion that mimicks the dynamics of music itself with the cycles of intensity, valence, and tone that rise and fall over time. \n",
    "\n",
    "**Pettijohn et al. (2010) Music for the Seasons: Seasonal Music Preferences in College Students** is a central piece of prior work that directly links seasons to musical preference. In their paper, they describe two studies with undergraduate participants, where students were primed to have different seasons in mind. In the first study, they used a winter vs. summer reading scenario, and in the second they had students write about their own fall, winter, spring, or summer experiences. They then reported their preffered types of music, where the results supported the researchers' hypotheses that seasonal context would shift preferences toward reflexive and complex music in fall and winter, and toward energetic and upbeat music for spring and summer<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4). This paper provides a strong foundation for investigating whether large-scale music trends from the Billboard Top100 also follow this shift from across different seasons. \n",
    "\n",
    "There is, however, some opposition to this theory. **Winthorst et al. (2020) Seasonality of mood and affect in a large general population sample** is a clear counter example to our premise- that seasons influence mood. The researchers studied mood and emotional well-being in adults to see if there were real differences in mood across the seasons. They measured positive and negative affect and depressive symptoms using questionaires. They found that season-to-season differences were very small and the evidence was not strong enough to say that seasons dramatically change mood for the great majority of people. The only meaningful effect was due to the personality trait neuroticism, but with only modest effects<a name=\"cite_ref-5\"></a>[<sup>5</sup>](#cite_note-5). This, very clearly, seems to contradict our earlier claim on which we based our research project. While we cannot directly test to confirm or reject their findings, if our results yield a difference of audio features that simmilarly match the findings of Pettijohn et al. (2010), then we may be able to assume some relationship between the two. \n",
    "\n",
    "References: \n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Clifton, Thomas. “Music and the a Priori.” Journal of Music Theory 17, no. 1 (1973): 66–85. https://doi.org/10.2307/843118. \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Silviya Y. 2024. “The Psychology of Music: How Different Genres Affect Mood and Emotions.” HOME. Indigo Music. September 17, 2024. https://indigomusic.com/feature/the-psychology-of-music-how-different-genres-affect-mood-and-emotions.\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) “Winter Depression Research Clinic.” 2025. Psychiatry. 2025. https://medicine.yale.edu/psychiatry/research/clinics-and-programs/winter-depression/.\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Pettijohn, T.F., Williams, G.M. & Carter, T.C. Music for the Seasons: Seasonal Music Preferences in College Students. Curr Psychol 29, 328–345 (2010). https://doi.org/10.1007/s12144-010-9092-8\n",
    "5. <a name=\"cite_note-5\"></a> [^](#cite_ref-5) Winthorst, Wim H et al. “Seasonality of mood and affect in a large general population sample.” PloS one vol. 15,9 e0239033. September 14, 2020. doi:10.1371/journal.pone.0239033"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect a moderate correlation between music preferences and seasonal mood variation. As people's mood and energy change with the seasons, they often choose music that matches how they feel or helps manage their emotions. As a result, music listened to in winter (when moods are generally lower) tends to have lower tempo, valence, and energy, while music listened to in the summer (when moods are higher) tends to be more energetic, have a higher tempo, and higher valence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading billboard_all.json:   0%|          | 0.00/4.12M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading billboard_all.json: 9.46MB [00:00, 94.6MB/s]                   \u001b[A\n",
      "Downloading billboard_all.json: 24.1MB [00:00, 125MB/s] \u001b[A\n",
      "Downloading billboard_all.json: 39.8MB [00:00, 139MB/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: billboard_all.json\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/mhollingshead/billboard-hot-100/main/all.json', 'filename':'billboard_all.json'},\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('data/00-raw/billboard_all.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for chart in data:\n",
    "    chart_date = chart[\"date\"]\n",
    "    for song in chart[\"data\"]:\n",
    "        song[\"date\"] = chart_date\n",
    "        rows.append(song)\n",
    "\n",
    "billboard_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31300, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df[\"date\"] = pd.to_datetime(billboard_df[\"date\"])\n",
    "\n",
    "##Filter for years 2020–2025\n",
    "billboard_df = billboard_df[\n",
    "    (billboard_df[\"date\"].dt.year >= 2020) &\n",
    "    (billboard_df[\"date\"].dt.year <= 2025)\n",
    "]\n",
    "\n",
    "billboard_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>this_week</th>\n",
       "      <th>last_week</th>\n",
       "      <th>peak_position</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320387</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320388</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320389</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320390</th>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>Burl Ives</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320391</th>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     song        artist  this_week  last_week  \\\n",
       "320387    All I Want For Christmas Is You  Mariah Carey          1        1.0   \n",
       "320388  Rockin' Around The Christmas Tree    Brenda Lee          2        2.0   \n",
       "320389                   Jingle Bell Rock   Bobby Helms          3        9.0   \n",
       "320390            A Holly Jolly Christmas     Burl Ives          4        6.0   \n",
       "320391                            Circles   Post Malone          5        3.0   \n",
       "\n",
       "        peak_position  weeks_on_chart       date  \n",
       "320387              1              37 2020-01-04  \n",
       "320388              2              32 2020-01-04  \n",
       "320389              3              30 2020-01-04  \n",
       "320390              4              15 2020-01-04  \n",
       "320391              1              17 2020-01-04  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df.shape\n",
    "billboard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song                 0\n",
       "artist               0\n",
       "this_week            0\n",
       "last_week         4888\n",
       "peak_position        0\n",
       "weeks_on_chart       0\n",
       "date                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>this_week</th>\n",
       "      <th>last_week</th>\n",
       "      <th>peak_position</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320387</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320388</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320389</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320390</th>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>Burl Ives</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320391</th>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     song        artist  this_week  last_week  \\\n",
       "320387    All I Want For Christmas Is You  Mariah Carey          1        1.0   \n",
       "320388  Rockin' Around The Christmas Tree    Brenda Lee          2        2.0   \n",
       "320389                   Jingle Bell Rock   Bobby Helms          3        9.0   \n",
       "320390            A Holly Jolly Christmas     Burl Ives          4        6.0   \n",
       "320391                            Circles   Post Malone          5        3.0   \n",
       "\n",
       "        peak_position  weeks_on_chart       date  season  \n",
       "320387              1              37 2020-01-04  Winter  \n",
       "320388              2              32 2020-01-04  Winter  \n",
       "320389              3              30 2020-01-04  Winter  \n",
       "320390              4              15 2020-01-04  Winter  \n",
       "320391              1              17 2020-01-04  Winter  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Spring\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Fall\"\n",
    "\n",
    "billboard_df[\"season\"] = billboard_df[\"date\"].apply(get_season)\n",
    "\n",
    "billboard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_df.to_csv(\"data/02-processed/billboard_2020_2025_cleaned.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "**Dataset Description**\n",
    "The Spotify audio features dataset provides a matching set of quantitative measurements that describe the musical and acoustic properties of unique tracks. These features are produced by Spotify's internal data and algorithmic analysis to extract standardized metrics. For this project, our primary focus in three variables- valence, energy, and tempo- which captures different dimensions of musical expression. \n",
    "\n",
    "Valence and Energy are unitless scores ranging from 0.0 to 1.0, where valence represents the \"positivity\" of a track and energy measures intesnity and activity level of the track. Songs with high valence will sound happy and/or cheerful, while high-energy songs will feel loud, fast, and dynamic. Tempo is measured in units of beats oer minute (BPM) and reflects the speed of the underlying beat. Together, these metrics will allow us to quanitify emotional and structural aspects of music across different seasons. \n",
    "\n",
    "Although valence, energy, and tempo are the core features for this project, Spotify offers a wide range of additional metrics like danceability, loudness, mode, speechiness, acousticness, etc. These features are not used directly in the project analysis, but are part of the audio features that will be extracted.\n",
    "\n",
    "**Dataset Concerns and Limitations**\n",
    "There are key limitations that must be considered when working with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Token \n",
    "To pull the audio feature data from spotify, an access token must be generated using both the client and secret IDs from the developer app created on spotify for this project. Using Anaconda promp, we set environment cariables to represent these IDs to avoid publicly sharing this information. We then have to encode these strings for formatting purposes, then request a token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your access token: BQBXsPrm5-i00CdM4pHc54gnx1l40pfOQKP0YwK-9KV1gPPJcTaohgbvO6TNdmT8Tmk76ZDl8LIxtzeRfcB7n_wdwjEipwWRm_TNR2P7k7QQR80roSwo3BVgIhG38SHobmTVoePoQvk\n"
     ]
    }
   ],
   "source": [
    "# first we must create a unique-song artist pairs dataset to ensure the API does not double count\n",
    "unique_tracks = billboard_df[['song', 'artist']].drop_duplicates()\n",
    "\n",
    "#pull access token from spotify api app on spotify developer (THANK YOU SO MUCH WORLD WIDE WEB OMGOMGOMGOMG THIS TOOK TOO LONG)\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "#for now we use these if jupyter not started from local machine (anaconda) \n",
    "client_id = \"6ac8d9c25e16499b9882d5002ec10e79\"\n",
    "client_secret = \"43ac1d5d81484b119d274bae7a1065db\"\n",
    "# client_id = os.getenv(\"SPOTIFY_CLIENT_ID\")\n",
    "# client_secret = os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n",
    "\n",
    "# Encode client ID and secret\n",
    "auth_str = f\"{client_id}:{client_secret}\"\n",
    "b64_auth_str = base64.b64encode(auth_str.encode()).decode()\n",
    "\n",
    "# Request token\n",
    "token_url = \"https://accounts.spotify.com/api/token\"\n",
    "headers = {\"Authorization\": f\"Basic {b64_auth_str}\", \"Conteynt-Type\": \"application/x-www-form-urlencoded\"}\n",
    "data = {\"grant_type\": \"client_credentials\"}\n",
    "\n",
    "response = requests.post(token_url, headers=headers, data=data)\n",
    "access_token = response.json()[\"access_token\"]\n",
    "\n",
    "print(\"Your access token:\", access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/models.py:965\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;66;03m# used.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m unique_tracks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspotify_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43munique_tracks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_track_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msong\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#Download Spotify Audio Features in batches\u001b[39;00m\n\u001b[1;32m     16\u001b[0m ids \u001b[38;5;241m=\u001b[39m unique_tracks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspotify_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m unique_tracks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspotify_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m unique_tracks\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43msearch_track_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msong\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#Download Spotify Audio Features in batches\u001b[39;00m\n\u001b[1;32m     16\u001b[0m ids \u001b[38;5;241m=\u001b[39m unique_tracks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspotify_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36msearch_track_id\u001b[0;34m(song, artist)\u001b[0m\n\u001b[1;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msong\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m artist:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.spotify.com/v1/search?q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&type=track&limit=1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtracks\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/requests/models.py:973\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 973\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# search spotify to obtain track IDs for every track and first pull an access token\n",
    "headers = {\"Authorization\" : f\"Bearer {access_token}\"}\n",
    "\n",
    "def search_track_id(song, artist):\n",
    "    query = f\"track:{song} artist:{artist}\"\n",
    "    url = f\"https://api.spotify.com/v1/search?q={query}&type=track&limit=1\"\n",
    "    r = requests.get(url, headers=headers).json()\n",
    "    try: \n",
    "        return r['tracks']['items'][0]['id']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "unique_tracks['spotify_id'] = unique_tracks.apply(lambda row: search_track_id(row['song'], row['artist']), axis=1)\n",
    "\n",
    "#Download Spotify Audio Features in batches\n",
    "ids = unique_tracks['spotify_id'].dropna().unique().tolist()\n",
    "\n",
    "audio_features = []\n",
    "\n",
    "for chunk in range (0, len(ids), 50):\n",
    "    batch = ids[chunk: chunk+50]\n",
    "    id_string = \",\".join(batch)\n",
    "    url = f\"https://api.spotify.com/v1/audio-features?ids={id_string}\"\n",
    "    r = requests.get(url, headers=headers).json()\n",
    "    audio_features.extend(r['audio_features'])\n",
    "\n",
    "#now, return only 3 features\n",
    "relevant_features = pd.DataFrame(audio_features)\n",
    "relevant_features = relevant_features[['id', 'valence', 'energy', 'tempo']]\n",
    "\n",
    "relevant_features.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *We will do our best to respond to any and all communication within a reasonable time frame (within roughly half a day)*\n",
    "* *On important days (e.g. submission days and the day before submission is due) we will do our best to respond more readily (within roughly 2-3 hours)*\n",
    "* *Any disagreements on the direction of the project, or of any of its individual components, will be resolved by a team vote. By agreeing to write your name in the author's section, you are agreeing to this clause.*\n",
    "* *We must agree to not speak down on anyone, regardless of how trivial a question may seem to you. We will be helpful and respectful.*\n",
    "* *We will contribute to every team meeting by proposing ideas, regardless of if they're fully fleshed out or not. Input from every member is valued equally.*\n",
    "* *HONOR DEADLINES!! When things slip (and they will), and if you **NEED** to focus on other work or your job, communicate that clearly to other members. If deadlines become unrealistic, we will be respectful and do our best to cover for the work you need to put down.*\n",
    "* *Miscommunications will happen, do not assume the worst of the other. We will resolve conflicts collaboratively and work towards solutions that respect everyone's perspective.*\n",
    "* *For major code changes/document updates, please use a branch and let everyone know ahead of time before you commit and push to master. Make an announcement on the Discord and/or group text to make sure everyone is aware and can cleanly address any potential conflicts.*\n",
    "* *Respect Each other's time and boundaries. We acknowledge that we all have responsibilies outside of this project, so it cannot be expected of someone to fulfill a last minute demand unless they consent.*\n",
    "* *This list is neither extensive nor exauhstive. As we work on this project, new expectations/erratums/or removals of an expectation can be proposed, discussed, and added as we see fit.* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
